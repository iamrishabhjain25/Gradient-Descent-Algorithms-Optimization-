{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20i190008_IE684_Lab7_Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObSqafj88SF"
      },
      "source": [
        "$\\large\\textbf{The need for the regularization}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv31peQo8w4W"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from numpy import random\r\n",
        "from sklearn.datasets import load_digits\r\n",
        "\r\n",
        "random.seed(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcGVlK7u2OBD"
      },
      "source": [
        "### $\\textbf{General Code}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V562tg_8moon"
      },
      "source": [
        "def evalf(A,x,y,n_feat, n, lamb):\r\n",
        "  assert type(A) is np.ndarray and A.shape == (n, n_feat)\r\n",
        "  assert type(x) is np.ndarray and x.shape == (n_feat,1)\r\n",
        "  assert type(y) is np.ndarray and y.shape == (n,1)\r\n",
        "  assert type(n_feat) is int and n_feat >0\r\n",
        "  assert type(n) is int and n >0\r\n",
        "  assert lamb > 0 \r\n",
        "\r\n",
        "  f = np.matmul(A,x) - y\r\n",
        "\r\n",
        "  return 0.5*(np.linalg.norm(f))**2  + 0.5*lamb*(np.matmul(x.T , x))\r\n",
        "\r\n",
        "\r\n",
        "def evalg(A,x,y,n_feat, n, lamb):\r\n",
        "  assert type(A) is np.ndarray and A.shape == (n, n_feat)\r\n",
        "  assert type(x) is np.ndarray and x.shape == (n_feat,1)\r\n",
        "  assert type(y) is np.ndarray and y.shape == (n,1)\r\n",
        "  assert type(n_feat) is int and n_feat >0\r\n",
        "  assert type(n) is int and n >0\r\n",
        "  assert lamb >= 0\r\n",
        "\r\n",
        "  d = np.matmul(A,x) - y\r\n",
        "  g = np.matmul(A.T , d) + lamb*x\r\n",
        "\r\n",
        "  return g\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def evalh(A,x,y,n_feat, n, lamb):\r\n",
        "  assert type(A) is np.ndarray and A.shape == (n, n_feat)\r\n",
        "  assert type(x) is np.ndarray and x.shape == (n_feat,1)\r\n",
        "  assert type(y) is np.ndarray and y.shape == (n,1)\r\n",
        "  assert type(n_feat) is int and n_feat >0\r\n",
        "  assert type(n) is int and n >0\r\n",
        "\r\n",
        "  h = np.matmul(A.T , A) + lamb*np.identity(n_feat)\r\n",
        "\r\n",
        "  return h\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpQQ0U6U2gHU"
      },
      "source": [
        "def compute_steplength_backtracking_scaled_direction(A,x,y, n_feat, n ,lamb  ,gradf, direction, alpha_start, rho, gamma): #add appropriate arguments to the function \r\n",
        "  assert type(x) is np.ndarray and x.shape == (n_feat,1)\r\n",
        "  assert type(gradf) is np.ndarray and gradf.shape == (n_feat,1)\r\n",
        "  assert type(direction) is np.ndarray and direction.shape == (n_feat, n_feat)\r\n",
        "  assert type(alpha_start) is float and alpha_start>=0. \r\n",
        "  assert type(rho) is float and rho>=0.\r\n",
        "  assert type(gamma) is float and gamma>=0. \r\n",
        "\r\n",
        "  alpha = alpha_start\r\n",
        "  p = -gradf\r\n",
        "\r\n",
        "  while (evalf(A, x + alpha*np.matmul(direction,p), y, n_feat, n,lamb) > (evalf(A,x,y,n_feat,n,lamb) + gamma * alpha * np.matmul(gradf.T, np.matmul(direction, p))) ):\r\n",
        "    alpha = alpha*rho\r\n",
        " \r\n",
        "  return alpha\r\n",
        "\r\n",
        "\r\n",
        "#line search type \r\n",
        "CONSTANT_STEP_LENGTH = 3\r\n",
        "BACKTRACKING_LINE_SEARCH = 2\r\n",
        "EXACT_LINE_SEARCH = 1\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def find_minimizer_Newtonmethod(A, start_x, y, n_feat,  n,lamb, tol, line_search_type, *args):\r\n",
        "  #Input: start_x is a numpy array of size n, tol denotes the tolerance and is a positive float value\r\n",
        "  assert type(A) is np.ndarray and A.shape == (n, n_feat)\r\n",
        "  assert type(start_x) is np.ndarray and start_x.shape == (n_feat,1)\r\n",
        "  assert type(y) is np.ndarray and y.shape == (n,1)\r\n",
        "  assert type(n_feat) is int and n_feat >0\r\n",
        "  assert type(n) is int and n >0\r\n",
        "  assert type(tol) is float and tol>=0 \r\n",
        "  \r\n",
        "  x = start_x\r\n",
        "  g_x = evalg(A,x,y,n_feat,n,lamb)\r\n",
        "  \r\n",
        "\r\n",
        "  if line_search_type == BACKTRACKING_LINE_SEARCH:\r\n",
        "    if args is None:\r\n",
        "      err_msg = 'Line search type: BACKTRACKING_LINE_SEARCH, but did not receive any args. Please check!'\r\n",
        "      raise ValueError(err_msg)\r\n",
        "    elif len(args)<3 :\r\n",
        "      err_msg = 'Line search type: BACKTRACKING_LINE_SEARCH, but did not receive three args. Please check!'\r\n",
        "      raise ValueError(err_msg)\r\n",
        "    else:\r\n",
        "      alpha_start = float(args[0])\r\n",
        "      rho = float(args[1])\r\n",
        "      gamma = float(args[2])\r\n",
        "  k = 0\r\n",
        "  x_k = []\r\n",
        "  \r\n",
        "  #print('iter:',k,  ' f(x):', evalf(x,n), ' gradient norm:', np.linalg.norm(g_x))\r\n",
        "\r\n",
        "  while (np.linalg.norm(g_x) > tol):\r\n",
        "\r\n",
        "    d = np.linalg.inv(evalh(A,x,y,n_feat,n,lamb))\r\n",
        "\r\n",
        "    if line_search_type == BACKTRACKING_LINE_SEARCH:\r\n",
        "      step_length = compute_steplength_backtracking_scaled_direction(A,x,y,n_feat,n,lamb,g_x, d , alpha_start,rho, gamma)\r\n",
        " \r\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: \r\n",
        "      step_length = 1.0\r\n",
        " \r\n",
        "    else:  \r\n",
        "      raise ValueError('Line search type unknown. Please check!')\r\n",
        " \r\n",
        "    x = np.subtract(x, step_length * np.matmul(d,g_x)) \r\n",
        "    k += 1 \r\n",
        "    x_k.append(x)\r\n",
        "    g_x = evalg(A,x,y,n_feat,n,lamb)\r\n",
        "  \r\n",
        "  return x, k, x_k\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def find_minimizer_BFGS(A, start_x, y, n_feat, n,lamb, tol,line_search_type,*args):\r\n",
        "  assert type(A) is np.ndarray and A.shape == (n, n_feat)\r\n",
        "  assert type(start_x) is np.ndarray and start_x.shape == (n_feat,1)\r\n",
        "  assert type(y) is np.ndarray and y.shape == (n,1)\r\n",
        "  assert type(n_feat) is int and n_feat >0\r\n",
        "  assert type(n) is int and n >0\r\n",
        "  assert type(tol) is float and tol>=0 \r\n",
        "\r\n",
        "\r\n",
        "  x = start_x\r\n",
        "  k = 0\r\n",
        "  g_new = evalg(A,x,y,n_feat,n,lamb)\r\n",
        "  B = np.identity(n_feat)\r\n",
        "  x_k = []  \r\n",
        "\r\n",
        "  if line_search_type == BACKTRACKING_LINE_SEARCH:\r\n",
        "    if args is None:\r\n",
        "      err_msg = 'Line search type: BACKTRACKING_LINE_SEARCH, but did not receive any args. Please check!'\r\n",
        "      raise ValueError(err_msg)\r\n",
        "    elif len(args)<3 :\r\n",
        "      err_msg = 'Line search type: BACKTRACKING_LINE_SEARCH, but did not receive three args. Please check!'\r\n",
        "      raise ValueError(err_msg)\r\n",
        "    else:\r\n",
        "      alpha_start = float(args[0])\r\n",
        "      rho = float(args[1])\r\n",
        "      gamma = float(args[2])\r\n",
        "\r\n",
        "  while (np.linalg.norm(g_new) > tol):\r\n",
        "\r\n",
        "    d = B\r\n",
        "\r\n",
        "    if line_search_type == BACKTRACKING_LINE_SEARCH:\r\n",
        "      step_length = compute_steplength_backtracking_scaled_direction(A,x,y,n_feat,n,lamb ,g_new, d , alpha_start,rho, gamma)\r\n",
        " \r\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: \r\n",
        "      step_length = 1.0\r\n",
        " \r\n",
        "    else:  \r\n",
        "      raise ValueError('Line search type unknown. Please check!')\r\n",
        "      \r\n",
        "    g_old = evalg(A,x,y,n_feat,n,lamb)\r\n",
        "    p = np.matmul(-1*B, g_old)\r\n",
        "    x = x + step_length * p\r\n",
        "    s = step_length * p\r\n",
        "    g_new = evalg(A,x,y,n_feat,n,lamb)\r\n",
        "    y_k = g_new - g_old\r\n",
        "\r\n",
        "    mu = 1 / (np.matmul(y_k.T,s))\r\n",
        "    term1 = np.identity(n_feat) - mu * np.matmul(s,y_k.T)\r\n",
        "    term2 = np.identity(n_feat) - mu * np.matmul(y_k, s.T)\r\n",
        "\r\n",
        "    B = np.matmul(term1, np.matmul(B ,term2))  +  mu * np.matmul(s,s.T)\r\n",
        "    \r\n",
        "    k = k + 1\r\n",
        "    x_k.append(x)\r\n",
        "    \r\n",
        "\r\n",
        "  return x, k, x_k\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xndO0FtpdSlv"
      },
      "source": [
        "$\\textbf{Solving by Newton's method with $\\lambda$ = 0 (without regularization) and with $\\lambda$ = 0.1 }$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfHnoBb2eg8q"
      },
      "source": [
        "digits = load_digits()\r\n",
        "\r\n",
        "print(digits.data.shape)\r\n",
        "print(digits.target.shape)\r\n",
        "\r\n",
        "N = digits.data.shape[0]\r\n",
        "d = digits.data.shape[1]\r\n",
        "A = digits.data\r\n",
        "y = 1.0 * np.ones([A.shape[0],1])\r\n",
        "\r\n",
        "for i in range(digits.target.shape[0]):\r\n",
        "  y[i] = digits.target[i]\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2V172XodfLM",
        "outputId": "37752a94-cb20-4a46-b037-3d38e6687a04"
      },
      "source": [
        "my_x = np.zeros((A.shape[1],1))\r\n",
        "lamb = [0, 0.1]\r\n",
        "my_tol = 10e-5\r\n",
        "alpha = 0.9\r\n",
        "rho = 0.5\r\n",
        "gamma = 0.5\r\n",
        "\r\n",
        "try:\r\n",
        "  x_0 , k_0 , x_k0 = find_minimizer_Newtonmethod(A,my_x,y,d,N,lamb[0],my_tol,BACKTRACKING_LINE_SEARCH, alpha, rho, gamma)\r\n",
        "except Exception as e:\r\n",
        "  print('Error : ',e)\r\n",
        "\r\n",
        "x_1 , k_1 , x_k1 = find_minimizer_Newtonmethod(A,my_x,y,d,N,lamb[1],my_tol,BACKTRACKING_LINE_SEARCH, alpha, rho, gamma)\r\n",
        "\r\n",
        "print('Results :-')\r\n",
        "print('---')\r\n",
        "\r\n",
        "print('With $\\lambda$ =0 , ERROR : Singular matrix \\n ')\r\n",
        "print('With $\\lambda$ =0.1 , x_opt = ',x_1.T , '\\n\\n and the number of iterations taken is,' , k_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error :  Singular matrix\n",
            "Results :-\n",
            "---\n",
            "With $\\lambda$ =0 , ERROR : Singular matrix \n",
            " \n",
            "With $\\lambda$ =0.1 , x_opt =  [[ 0.00000000e+00  9.72176393e-02 -4.25221013e-03 -7.65725749e-03\n",
            "   7.49359298e-02  1.13924666e-02 -2.68134811e-02 -8.48370171e-03\n",
            "   9.91208545e-01 -2.87397984e-02  1.18690196e-01  6.61518400e-02\n",
            "  -5.57615717e-02 -6.96340237e-02  9.62813519e-02  2.56470858e-01\n",
            "  -7.28979627e-01  2.42825856e-02  7.72526071e-02 -2.33770172e-02\n",
            "  -5.63320407e-02  5.71246069e-02 -4.84767009e-02 -2.70744170e-01\n",
            "  -8.60889238e-01 -1.49941949e-01  5.64334649e-02  8.96806467e-02\n",
            "   8.39114973e-02  9.85243348e-02  1.64759992e-03 -2.82145749e+00\n",
            "   0.00000000e+00 -1.54275472e-01 -9.36618641e-03  1.39528972e-01\n",
            "  -3.69438111e-02  5.46098301e-02 -9.13188784e-03  0.00000000e+00\n",
            "   1.07369006e-01  1.23996365e-01 -1.37231270e-02  5.34871565e-03\n",
            "   1.31237767e-01  5.50202750e-02  2.24738205e-02  7.53480641e-03\n",
            "   5.95009063e-01  2.42332551e-02  1.44538782e-03 -6.21495531e-02\n",
            "  -2.06985396e-01 -3.38924139e-02  1.05491772e-01 -1.40375388e-01\n",
            "  -8.25290583e-01 -1.14990629e-01  2.09661777e-02 -4.36766596e-02\n",
            "   1.87173457e-02 -6.66050522e-02  1.19523791e-02 -5.28287670e-02]] \n",
            "\n",
            " and the number of iterations taken is, 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXp6IHNhjyoy"
      },
      "source": [
        "$\\textbf{Solving by BFGS method with $\\lambda$ = 0 (without regularization) and with $\\lambda$ = 0.1 }$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I974LmPxgo2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600cee56-6202-469d-dda2-0fa42d91fbde"
      },
      "source": [
        "x_0 , k_0 , x_k0 = find_minimizer_BFGS(A,my_x,y,d,N,lamb[1],my_tol,BACKTRACKING_LINE_SEARCH, alpha, rho, gamma)\r\n",
        "x_1 , k_1 , x_k1 = find_minimizer_BFGS(A,my_x,y,d,N,lamb[1],my_tol,BACKTRACKING_LINE_SEARCH, alpha, rho, gamma)\r\n",
        "\r\n",
        "print('For the BFGS Methods Without regualrization')\r\n",
        "print('\\n')\r\n",
        "print('Optimal x : ', x_0.T)\r\n",
        "print('Number of itertion : ', k_0)\r\n",
        "\r\n",
        "print('--------')\r\n",
        "\r\n",
        "print('For the BFGS Methods With lambda = 0.1')\r\n",
        "print('\\n')\r\n",
        "print('Optimal x : ', x_1.T)\r\n",
        "print('Number of itertion : ', k_1)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the BFGS Methods Without regualrization\n",
            "\n",
            "\n",
            "Optimal x :  [[ 0.00000000e+00  9.72176390e-02 -4.25220995e-03 -7.65725748e-03\n",
            "   7.49359297e-02  1.13924666e-02 -2.68134811e-02 -8.48370168e-03\n",
            "   9.91208546e-01 -2.87397983e-02  1.18690196e-01  6.61518400e-02\n",
            "  -5.57615717e-02 -6.96340237e-02  9.62813520e-02  2.56470858e-01\n",
            "  -7.28979638e-01  2.42825855e-02  7.72526070e-02 -2.33770172e-02\n",
            "  -5.63320407e-02  5.71246069e-02 -4.84767009e-02 -2.70744170e-01\n",
            "  -8.60889213e-01 -1.49941949e-01  5.64334649e-02  8.96806467e-02\n",
            "   8.39114973e-02  9.85243348e-02  1.64759987e-03 -2.82145750e+00\n",
            "   0.00000000e+00 -1.54275472e-01 -9.36618643e-03  1.39528972e-01\n",
            "  -3.69438111e-02  5.46098302e-02 -9.13188786e-03  0.00000000e+00\n",
            "   1.07369006e-01  1.23996365e-01 -1.37231270e-02  5.34871566e-03\n",
            "   1.31237767e-01  5.50202749e-02  2.24738204e-02  7.53480609e-03\n",
            "   5.95009064e-01  2.42332550e-02  1.44538782e-03 -6.21495531e-02\n",
            "  -2.06985396e-01 -3.38924139e-02  1.05491772e-01 -1.40375388e-01\n",
            "  -8.25290577e-01 -1.14990629e-01  2.09661774e-02 -4.36766595e-02\n",
            "   1.87173457e-02 -6.66050522e-02  1.19523792e-02 -5.28287672e-02]]\n",
            "Number of itertion :  70\n",
            "--------\n",
            "For the BFGS Methods With lambda = 0.1\n",
            "\n",
            "\n",
            "Optimal x :  [[ 0.00000000e+00  9.72176390e-02 -4.25220995e-03 -7.65725748e-03\n",
            "   7.49359297e-02  1.13924666e-02 -2.68134811e-02 -8.48370168e-03\n",
            "   9.91208546e-01 -2.87397983e-02  1.18690196e-01  6.61518400e-02\n",
            "  -5.57615717e-02 -6.96340237e-02  9.62813520e-02  2.56470858e-01\n",
            "  -7.28979638e-01  2.42825855e-02  7.72526070e-02 -2.33770172e-02\n",
            "  -5.63320407e-02  5.71246069e-02 -4.84767009e-02 -2.70744170e-01\n",
            "  -8.60889213e-01 -1.49941949e-01  5.64334649e-02  8.96806467e-02\n",
            "   8.39114973e-02  9.85243348e-02  1.64759987e-03 -2.82145750e+00\n",
            "   0.00000000e+00 -1.54275472e-01 -9.36618643e-03  1.39528972e-01\n",
            "  -3.69438111e-02  5.46098302e-02 -9.13188786e-03  0.00000000e+00\n",
            "   1.07369006e-01  1.23996365e-01 -1.37231270e-02  5.34871566e-03\n",
            "   1.31237767e-01  5.50202749e-02  2.24738204e-02  7.53480609e-03\n",
            "   5.95009064e-01  2.42332550e-02  1.44538782e-03 -6.21495531e-02\n",
            "  -2.06985396e-01 -3.38924139e-02  1.05491772e-01 -1.40375388e-01\n",
            "  -8.25290577e-01 -1.14990629e-01  2.09661774e-02 -4.36766595e-02\n",
            "   1.87173457e-02 -6.66050522e-02  1.19523792e-02 -5.28287672e-02]]\n",
            "Number of itertion :  70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6UM8GC3klB-"
      },
      "source": [
        "***Remarks :***  *We observe that for the newtons's method we get a singular hessian matrix without regularization and hence we cannnot calculate the optimal value of x. But we get the optimal value of x when we use newton's method with regularization.*\r\n",
        "\r\n",
        "*We observe that for the BFGS methods, we get the answer in both cases. i.e with and without regualrization.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5hzQXMglJsi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}